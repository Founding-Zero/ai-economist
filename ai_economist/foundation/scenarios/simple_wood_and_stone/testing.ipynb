{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "\n",
    "with open(\"/Users/henry/Documents/new-ml/ai-economist/tutorials/rllib/test/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_config = config.get(\"env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside covid19_components.py: 0 GPUs are available.\n",
      "No GPUs found! Running the simulation on a CPU.\n",
      "Inside covid19_env.py: 0 GPUs are available.\n",
      "No GPUs found! Running the simulation on a CPU.\n"
     ]
    }
   ],
   "source": [
    "from ai_economist import foundation\n",
    "from ai_economist.foundation.scenarios.simple_wood_and_stone.layout_from_file import LayoutFromFile\n",
    "\n",
    "env = foundation.make_env_instance(**env_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0', '1', '2', '3', 'p'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['time', 'flat', 'p0', 'p1', 'p2', 'p3', 'action_mask'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs['p'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def recursive_list_to_np_array(d):\n",
    "    if isinstance(d, dict):\n",
    "        new_d = {}\n",
    "        for k, v in d.items():\n",
    "            if isinstance(v, list):\n",
    "                new_d[k] = np.array(v)\n",
    "            elif isinstance(v, dict):\n",
    "                new_d[k] = recursive_list_to_np_array(v)\n",
    "            elif isinstance(v, (float, int, np.floating, np.integer)):\n",
    "                new_d[k] = np.array([v])\n",
    "            elif isinstance(v, np.ndarray):\n",
    "                new_d[k] = v\n",
    "            else:\n",
    "                raise AssertionError\n",
    "        return new_d\n",
    "    raise AssertionError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobs = recursive_list_to_np_array(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': array([0.]),\n",
       " 'flat': array([0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.  ],\n",
       "       dtype=float32),\n",
       " 'p0': array([0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " 'p1': array([0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " 'p2': array([0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " 'p3': array([0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " 'action_mask': array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.], dtype=float32)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nobs['p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from gym import spaces\n",
    "\n",
    "def _dict_to_spaces_dict(obs):\n",
    "        dict_of_spaces = {}\n",
    "        for k, v in obs.items():\n",
    "\n",
    "            # list of lists are listified np arrays\n",
    "            _v = v\n",
    "            if isinstance(v, list):\n",
    "                _v = np.array(v)\n",
    "            elif isinstance(v, (int, float, np.floating, np.integer)):\n",
    "                _v = np.array([v])\n",
    "\n",
    "            # assign Space\n",
    "            if isinstance(_v, np.ndarray):\n",
    "                x = float(1e20)\n",
    "                # Warnings for extreme values\n",
    "                if np.max(_v) > x:\n",
    "                    warnings.warn(\"Input is too large!\")\n",
    "                if np.min(_v) < -x:\n",
    "                    warnings.warn(\"Input is too small!\")\n",
    "                box = spaces.Box(low=-x, high=x, shape=_v.shape, dtype=_v.dtype)\n",
    "                low_high_valid = (box.low < 0).all() and (box.high > 0).all()\n",
    "\n",
    "                # This loop avoids issues with overflow to make sure low/high are good.\n",
    "                while not low_high_valid:\n",
    "                    x = x // 2\n",
    "                    box = spaces.Box(low=-x, high=x, shape=_v.shape, dtype=_v.dtype)\n",
    "                    low_high_valid = (box.low < 0).all() and (box.high > 0).all()\n",
    "\n",
    "                dict_of_spaces[k] = box\n",
    "\n",
    "            elif isinstance(_v, dict):\n",
    "                dict_of_spaces[k] = self._dict_to_spaces_dict(_v)\n",
    "            else:\n",
    "                raise TypeError\n",
    "        return spaces.Dict(dict_of_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['action_mask', 'flat', 'p0', 'p1', 'p2', 'p3', 'time'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_dict_to_spaces_dict(obs['p']).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['world-map', 'world-idx_map', 'time', 'flat', 'action_mask'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs['0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasConvLSTM(RecurrentTFModelV2):\n",
    "    \"\"\"\n",
    "    The model used in the paper \"The AI Economist: Optimal Economic Policy\n",
    "    Design via Two-level Deep Reinforcement Learning\"\n",
    "    (https://arxiv.org/abs/2108.02755)\n",
    "    We combine convolutional, fully connected, and recurrent layers to process\n",
    "    spatial, non-spatial, and historical information, respectively.\n",
    "    For recurrent components, each agent maintains its own hidden state.\n",
    "    \"\"\"\n",
    "\n",
    "    custom_name = \"keras_conv_lstm\"\n",
    "\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        super().__init__(obs_space, action_space, num_outputs, model_config, name)\n",
    "\n",
    "        input_emb_vocab = self.model_config[\"custom_options\"][\"input_emb_vocab\"]\n",
    "        emb_dim = self.model_config[\"custom_options\"][\"idx_emb_dim\"]\n",
    "        num_conv = self.model_config[\"custom_options\"][\"num_conv\"]\n",
    "        num_fc = self.model_config[\"custom_options\"][\"num_fc\"]\n",
    "        fc_dim = self.model_config[\"custom_options\"][\"fc_dim\"]\n",
    "        cell_size = self.model_config[\"custom_options\"][\"lstm_cell_size\"]\n",
    "        generic_name = self.model_config[\"custom_options\"].get(\"generic_name\", None)\n",
    "\n",
    "        self.cell_size = cell_size\n",
    "\n",
    "        if hasattr(obs_space, \"original_space\"):\n",
    "            obs_space = obs_space.original_space\n",
    "\n",
    "        if not isinstance(obs_space, Dict):\n",
    "            if isinstance(obs_space, Box):\n",
    "                raise TypeError(\n",
    "                    \"({}) Observation space should be a gym Dict.\"\n",
    "                    \" Is a Box of shape {}\".format(name, obs_space.shape)\n",
    "                )\n",
    "            raise TypeError(\n",
    "                \"({}) Observation space should be a gym Dict.\"\n",
    "                \" Is {} instead.\".format(name, type(obs_space))\n",
    "            )\n",
    "\n",
    "        # Define input layers\n",
    "        self._input_keys = []\n",
    "        non_conv_input_keys = []\n",
    "        input_dict = {}\n",
    "        conv_shape_r = None\n",
    "        conv_shape_c = None\n",
    "        conv_map_channels = None\n",
    "        conv_idx_channels = None\n",
    "        found_world_map = False\n",
    "        found_world_idx = False\n",
    "        for k, v in obs_space.spaces.items():\n",
    "            shape = (None,) + v.shape\n",
    "            input_dict[k] = tf.keras.layers.Input(shape=shape, name=k)\n",
    "            self._input_keys.append(k)\n",
    "            if k == _MASK_NAME:\n",
    "                pass\n",
    "            else:\n",
    "                non_conv_input_keys.append(k)\n",
    "\n",
    "        # Cell state and hidden state for the\n",
    "        # policy and value function networks.\n",
    "        state_in_h_p = tf.keras.layers.Input(shape=(cell_size,), name=\"h_pol\")\n",
    "        state_in_c_p = tf.keras.layers.Input(shape=(cell_size,), name=\"c_pol\")\n",
    "        state_in_h_v = tf.keras.layers.Input(shape=(cell_size,), name=\"h_val\")\n",
    "        state_in_c_v = tf.keras.layers.Input(shape=(cell_size,), name=\"c_val\")\n",
    "        seq_in = tf.keras.layers.Input(shape=(), name=\"seq_in\")\n",
    "\n",
    "        # Determine which of the inputs are treated as non-conv inputs\n",
    "        non_conv_inputs = tf.keras.layers.concatenate([input_dict[k] for k in non_conv_input_keys])\n",
    "\n",
    "        logits, values, state_h_p, state_c_p, state_h_v, state_c_v = (None,None,None,None,None,None,)\n",
    "\n",
    "        # Define the policy and value function models\n",
    "        for tag in [\"_pol\", \"_val\"]:\n",
    "            if tag == \"_pol\":\n",
    "                state_in = [state_in_h_p, state_in_c_p]\n",
    "            elif tag == \"_val\":\n",
    "                state_in = [state_in_h_v, state_in_c_v]\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "            dense = non_conv_inputs\n",
    "\n",
    "            # Preprocess observation with hidden layers and send to LSTM cell\n",
    "            for i in range(num_fc):\n",
    "                layer = tf.keras.layers.Dense(fc_dim, activation=tf.nn.relu, name=\"dense{}\".format(i + 1) + tag)\n",
    "                dense = layer(dense)\n",
    "\n",
    "            dense = tf.keras.layers.LayerNormalization(name=\"layer_norm\" + tag)(dense)\n",
    "\n",
    "            lstm_out, state_h, state_c = tf.keras.layers.LSTM(\n",
    "                cell_size, return_sequences=True, return_state=True, name=\"lstm\" + tag\n",
    "            )(inputs=dense, mask=tf.sequence_mask(seq_in), initial_state=state_in)\n",
    "\n",
    "            # Project LSTM output to logits or value\n",
    "            output = tf.keras.layers.Dense(\n",
    "                self.num_outputs if tag == \"_pol\" else 1,\n",
    "                activation=tf.keras.activations.linear,\n",
    "                name=\"logits\" if tag == \"_pol\" else \"value\",\n",
    "            )(lstm_out)\n",
    "\n",
    "            if tag == \"_pol\":\n",
    "                state_h_p, state_c_p = state_h, state_c\n",
    "                logits = apply_logit_mask(output, input_dict[_MASK_NAME])\n",
    "            elif tag == \"_val\":\n",
    "                state_h_v, state_c_v = state_h, state_c\n",
    "                values = output\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "        self.input_dict = input_dict\n",
    "\n",
    "        # This will be set in the forward_rnn() call below\n",
    "        self._value_out = None\n",
    "\n",
    "        for out in [logits, values, state_h_p, state_c_p, state_h_v, state_c_v]:\n",
    "            assert out is not None\n",
    "\n",
    "        # Create the RNN model\n",
    "        self.rnn_model = tf.keras.Model(\n",
    "            inputs=self._extract_input_list(input_dict)\n",
    "            + [seq_in, state_in_h_p, state_in_c_p, state_in_h_v, state_in_c_v],\n",
    "            outputs=[logits, values, state_h_p, state_c_p, state_h_v, state_c_v],\n",
    "        )\n",
    "        self.register_variables(self.rnn_model.variables)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
